<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=print><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.145.0"><meta name=generator content="Relearn 7.6.1+81b6d3c32c77aeecc29c4700d2123bd2fb3401c2"><meta name=description content="Scenario Description"><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops"><meta name=twitter:description content="Scenario Description"><meta property="og:url" content="https://splunk.github.io/observability-workshop/v5.96/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html"><meta property="og:site_name" content="Splunk Observability Cloud Workshops"><meta property="og:title" content="Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops"><meta property="og:description" content="Scenario Description"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops"><meta itemprop=description content="Scenario Description"><meta itemprop=dateModified content="2025-03-03T12:27:20+00:00"><meta itemprop=wordCount content="346"><title>Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops</title>
<link href=https://splunk.github.io/observability-workshop/v5.96/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html rel=canonical type=text/html title="Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops"><link href=/observability-workshop/v5.96/images/favicon.ico?1751877988 rel=icon type=image/x-icon sizes=any><link href=/observability-workshop/v5.96/css/auto-complete/auto-complete.min.css?1751877988 rel=stylesheet><script src=/observability-workshop/v5.96/js/auto-complete/auto-complete.min.js?1751877988 defer></script><script src=/observability-workshop/v5.96/js/search-lunr.min.js?1751877988 defer></script><script src=/observability-workshop/v5.96/js/search.min.js?1751877988 defer></script><script>window.relearn=window.relearn||{},window.relearn.index_js_url="/observability-workshop/v5.96/searchindex.en.js?1751877988"</script><script src=/observability-workshop/v5.96/js/lunr/lunr.min.js?1751877988 defer></script><script src=/observability-workshop/v5.96/js/lunr/lunr.stemmer.support.min.js?1751877988 defer></script><script src=/observability-workshop/v5.96/js/lunr/lunr.multi.min.js?1751877988 defer></script><script src=/observability-workshop/v5.96/js/lunr/lunr.en.min.js?1751877988 defer></script><script>window.relearn=window.relearn||{},window.relearn.contentLangs=["en"]</script><link href=/observability-workshop/v5.96/fonts/fontawesome/css/fontawesome-all.min.css?1751877988 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.96/fonts/fontawesome/css/fontawesome-all.min.css?1751877988 rel=stylesheet></noscript><link href=/observability-workshop/v5.96/css/perfect-scrollbar/perfect-scrollbar.min.css?1751877988 rel=stylesheet><link href=/observability-workshop/v5.96/css/theme.min.css?1751877988 rel=stylesheet><link href=/observability-workshop/v5.96/css/format-print.min.css?1751877988 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.min=`.min`,window.relearn.path="/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html",window.relearn.relBasePath="../../..",window.relearn.relBaseUri="../../../../..",window.relearn.absBaseUri="https://splunk.github.io/observability-workshop/v5.96",window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.disableInlineCopyToClipboard=!0,window.relearn.enableBlockCodeWrap=!0,window.relearn.getItem=(e,t)=>e.getItem(t),window.relearn.setItem=(e,t,n)=>e.setItem(t,n),window.relearn.removeItem=(e,t)=>e.removeItem(t),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`,window.relearn.themevariants=["auto","splunk-light","splunk-dark"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&(document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}})),window.relearn.markVariant())},window.relearn.markVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant");document.querySelectorAll(".R-variantswitcher select").forEach(t=>{t.value=e})},window.relearn.initVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant()</script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js crossorigin=anonymous></script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js crossorigin=anonymous></script><script>SplunkRum.init({realm:"us1",rumAccessToken:"Z8JjZ8iNiF4jSfNHvJIRJg",applicationName:"observability-workshop",deploymentEnvironment:"splunk.github.io",version:"1.0"}),SplunkSessionRecorder.init({app:"observability-workshop",realm:"us1",rumAccessToken:"Z8JjZ8iNiF4jSfNHvJIRJg"})</script></script><style>:root{--MAIN-WIDTH-MAX:130rem;--MENU-WIDTH-L:23rem}p{margin:.75rem 0}.highlight{max-height:500px;overflow-y:auto}pre:not(.mermaid){margin:0}</style></head><body class="mobile-support print" data-url=/observability-workshop/v5.96/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div><div class="topbar-button topbar-button-toc" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-list-alt"></i></button><div class=topbar-content><div class=topbar-content-wrapper></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v5.96/en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v5.96/en/ninja-workshops/index.html><span itemprop=name>Splunk4Ninjas Workshops</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Ingest Processor for Observability Cloud</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.96/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.96/en/ninja-workshops/9-solving-problems-with-o11y-cloud/6-summary/index.html title="Summary (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.96/en/ninja-workshops/11-ingest_processor_for_observability_cloud/1-getting-started/index.html title="Getting Started (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable ninja-workshops" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=ingest-processor-for-observability-cloud>Ingest Processor for Observability Cloud</h1><span class="badge cstyle blue badge-with-title"><span class=badge-title class=text-muted>Author
</span><span class=badge-content>Tim Hard</span></span><p>As infrastructure and application environments become exceedingly complex, the volume of data they generate continues to grow significantly. This increase in data volume and variety makes it challenging to gain actionable insights and can impact problem identification and troubleshooting efficiencies. Additionally, the cost of storing and accessing this data can skyrocket. Many data sources, particularly logs and events, provide critical visibility into system operations. However, in most cases, only a few details from these extensive logs are actually needed for effective monitoring and alerting.</p><p><strong>Common Challenges:</strong></p><ul><li>Increasing complexity of infrastructure and application environments.</li><li>Significant growth in data volume generated by these environments.</li><li>Challenges in gaining actionable insights from large volumes of data.</li><li>High costs associated with storing and accessing extensive data.</li><li>Logs and events provide critical visibility but often contain only a few essential details.</li></ul><p>To address these challenges, Splunk Ingest Processor provides a powerful new feature: the ability to convert log events into metrics. Metrics are more efficient to store and process, allowing for faster identification of issues, thereby reducing Mean Time to Detection (MTTD). When retaining the original log or event is necessary, they can be stored in cheaper storage solutions such as S3, reducing the overall cost of data ingestion and computation required for searching them.</p><p><strong>Solution:</strong></p><ul><li>Convert log events into metrics where possible.</li><li>Retain original logs or events in cheaper storage solutions if needed.</li><li>Utilize federated search for accessing and analyzing retained logs.</li></ul><p><strong>Outcomes:</strong></p><ul><li>Metrics are more efficient to store and process.</li><li>Faster identification of problems, reducing Mean Time to Detection (MTTD).</li><li>Lower overall data ingestion and computation costs.</li><li>Enhanced monitoring efficiency and resource optimization.</li><li>Maintain high visibility into system operations with reduced operational costs.</li></ul><p>In this workshop you&rsquo;ll have the opportunity to get hands on with Ingest Processor and Splunk Observability Cloud to see how it can be used to address the challenges outlined above.</p><details open class="box cstyle notices primary"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-lightbulb"></i>
Tip</summary><div class=box-content><p>The easiest way to navigate through this workshop is by using:</p><ul><li>the left/right arrows (<strong>&lt;</strong> | <strong>></strong>) on the top right of this page</li><li>the left (◀️) and right (▶️) cursor keys on your keyboard</li></ul></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of Ingest Processor for Observability Cloud</h1><article class=default><header class=headline></header><h1 id=getting-started>Getting Started</h1><p>During this <em><strong>technical</strong></em> Ingest Processor<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> for Splunk Observability Cloud workshop you will have the opportunity to get hands-on with Ingest Processor in Splunk Enterprise Cloud.</p><p>To simplify the workshop modules, a pre-configured Splunk Enterprise Cloud instance is provided.</p><p>The instance is pre-configured with all the requirements for creating an Ingest Processor pipeline.</p><p>This workshop will introduce you to the benefits of using Ingest Processor to convert robust logs to metrics and send those metrics to Splunk Observability Cloud. By the end of these technical workshops, you will have a good understanding of some key features and capabilities of Ingest Processor in Splunk Enterprise Cloud and the value of using Splunk Observability Cloud as a destination within an Ingest Processor pipeline.</p><p>Here are the instructions on how to access your pre-configured <a href=/observability-workshop/v5.96/en/ninja-workshops/11-ingest_processor_for_observability_cloud/1-getting-started/1-access-cloud-instances/index.html>Splunk Enterprise Cloud</a> instance.</p><p><a href=#R-image-4bd36eb1f0e0024ef1aae1ccc1031390 class=lightbox-link><img alt="Splunk Ingest Processor Architecture" class="lazy lightbox figure-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-4bd36eb1f0e0024ef1aae1ccc1031390><img alt="Splunk Ingest Processor Architecture" class="lazy lightbox lightbox-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png></a></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://docs.splunk.com/Documentation/SplunkCloud/9.3.2408/IngestProcessor/AboutIngestProcessorSolution rel=external target=_blank><strong>Ingest Processor</strong></a> is a data processing capability that works within your Splunk Cloud Platform deployment. Use the Ingest Processor to configure data flows, control data format, apply transformation rules prior to indexing, and route to destinations.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 1. Getting Started</h1><article class=default><header class=headline></header><h1 id=how-to-connect-to-your-workshop-environment>How to connect to your workshop environment</h1><ol><li>How to retrieve the URL for your Splunk Enterprise Cloud instances.</li><li>How to access the Splunk Observability Cloud workshop organization.</li></ol><hr><h2 id=1-splunk-cloud-instances>1. Splunk Cloud Instances</h2><p>There are three instances that will be used throughout this workshop which have already been provisioned for you:</p><ol><li>Splunk Enterprise Cloud</li><li>Splunk Ingest Processor (SCS Tenant)</li><li>Splunk Observability Cloud</li></ol><p>The Splunk Enterprise Cloud and Ingest Processor instances are hosted in <a href=https://show.splunk.com rel=external target=_blank>Splunk Show</a>. If you were invited to the workshop, you should have received an email with an invite to the event in <a href=https://show.splunk.com rel=external target=_blank>Splunk Show</a> or a link to the event will have been provided at the beginning of the workshop.</p><p>Login to Splunk Show using your <a href=https://login.splunk.com/ rel=external target=_blank>splunk.com</a> credentials. You should see the event for this workshop. Open the event to see the instance details for your Splunk Cloud and Ingest Processor instances.</p><details open class="box cstyle notices primary"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p>Take note of the <code>User Id</code> provided in your Splunk Show event details. This number will be included in the <code>sourcetype</code> that you will use for searching and filtering the Kubernetes data. Because this is a shared environment only use the participant number provided so that other participants data is not effected.</p></div></details><p><a href=#R-image-7b1415d5c11cd3f84f925c946d08f6d8 class=lightbox-link><img alt="Splunk Show Instance Information" class="lazy lightbox figure-image" loading=lazy src=../../images/show_instance_information.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-7b1415d5c11cd3f84f925c946d08f6d8><img alt="Splunk Show Instance Information" class="lazy lightbox lightbox-image" loading=lazy src=../../images/show_instance_information.png></a></p><h2 id=2-splunk-observability-cloud-instances>2. Splunk Observability Cloud Instances</h2><p>You should have also received an email to access the Splunk Observability Cloud workshop organization (You may need to check your spam folder). If you have not received an email, let your workshop instructor know. To access the environment click the <strong>Join Now</strong> button.</p><p><a href=#R-image-71b4532427ddc6f3414c2ad13be42531 class=lightbox-link><img alt="Splunk Observability Cloud Invitation" class="lazy lightbox figure-image" loading=lazy src=../../images/workshop_invitation.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-71b4532427ddc6f3414c2ad13be42531><img alt="Splunk Observability Cloud Invitation" class="lazy lightbox lightbox-image" loading=lazy src=../../images/workshop_invitation.png></a></p><details open class="box cstyle notices info"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-info-circle"></i>
Important</summary><div class=box-content><p>If you access the event before the workshop start time, your instances may not be available yet. Don&rsquo;t worry, they will be provided once the workshop begins.</p></div></details><p>Additionally, you have been invited to a Splunk Observability Cloud workshop organization. The invitation includes a link to the environment. If you don&rsquo;t have a Splunk Observability Cloud account already, you will be asked to create one. If you already have one, you can log in to the instance and, you will see the workshop organization in your available organizations.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article></section><article class=default><header class=headline></header><h1 id=how-ingest-processor-works>How Ingest Processor Works</h1><h6 id=system-architecture>System architecture</h6><p>The primary components of the Ingest Processor service include the Ingest Processor service and SPL2 pipelines that support data processing. The following diagram provides an overview of how the components of the Ingest Processor solution work together:</p><p><a href=#R-image-a3ecd9d5fb277ec6a252c27d028c65db class=lightbox-link><img alt="Splunk Ingest Processor Architecture" class="lazy lightbox figure-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-a3ecd9d5fb277ec6a252c27d028c65db><img alt="Splunk Ingest Processor Architecture" class="lazy lightbox lightbox-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png></a></p><h6 id=ingest-processor-service>Ingest Processor service</h6><p>The Ingest Processor service is a cloud service hosted by Splunk. It is part of the data management experience, which is a set of services that fulfill a variety of data ingest and processing use cases.</p><p>You can use the Ingest Processor service to do the following:</p><ul><li>Create and apply SPL2 pipelines that determine how each Ingest Processor processes and routes the data that it receives.</li><li>Define source types to identify the kind of data that you want to process and determine how the Ingest Processor breaks and merges that data into distinct events.</li><li>Create connections to the destinations that you want your Ingest Processor to send processed data to.</li></ul><h6 id=pipelines>Pipelines</h6><p>A pipeline is a set of data processing instructions written in SPL2. When you create a pipeline, you write a specialized SPL2 statement that specifies which data to process, how to process it, and where to send the results. When you apply a pipeline, the Ingest Processor uses those instructions to process all the data that it receives from data sources such as Splunk forwarders, HTTP clients, and logging agents.</p><p>Each pipeline selects and works with a subset of all the data that the Ingest Processor receives. For example, you can create a pipeline that selects events with the source type <code>cisco_syslog</code> from the incoming data, and then sends them to a specified index in Splunk Cloud Platform. This subset of selected data is called a partition. For more information, see <a href=http://docs.splunk.com/Documentation/SplunkCloud/latest/IngestProcessor/Architecture#Partitions rel=external target=_blank>Partitions</a>.</p><p>The Ingest Processor solution supports only the commands and functions that are part of the <code>IngestProcessor</code> profile. For information about the specific SPL2 commands and functions that you can use to write pipelines for Ingest Processor, see <a href=http://docs.splunk.com/Documentation/SplunkCloud/latest/IngestProcessor/PipelinesOverview rel=external target=_blank>Ingest Processor pipeline syntax</a>. For a summary of how the <code>IngestProcessor</code> profile supports different commands and functions compared to other SPL2 profiles, see the following pages in the <em>SPL2 Search Reference</em>:</p><ul><li><a href=http://docs.splunk.com/Documentation/SCS/current/SearchReference/CompatibilityQuickReferenceforSPL2commands rel=external target=_blank>Compatibility Quick Reference for SPL2 commands</a></li><li><a href=http://docs.splunk.com/Documentation/SCS/current/SearchReference/CompatibilityQuickReferenceforSPL2evaluationfunctions rel=external target=_blank>Compatibility Quick Reference for SPL2 evaluation functions</a></li></ul><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=create-an-ingest-pipeline>Create an Ingest Pipeline</h1><h2 id=scenario-overview>Scenario Overview</h2><p>In this scenario you will be playing the role of a Splunk Admin responsible for managing your organizations Splunk Enterprise Cloud environment. You recently worked with an internal application team on instrumenting their Kubernetes environment with Splunk APM and Infrastructure monitoring using OpenTelemetry to monitor their critical microservice applications.</p><p>The logs from the Kubernetes environment are also being collected and sent to Splunk Enter Prize Cloud. These logs include:</p><ul><li>Pod logs (application logs)</li><li>Kubernetes Events</li><li>Kubernetes Cluster Logs<ul><li>Control Plane Node logs</li><li>Worker Node logs</li><li>Audit Logs</li></ul></li></ul><p>As a Splunk Admin you want to ensure that the data you are collecting is optimized, so it can be analyzed in the most efficient way possible. Taking this approach accelerates troubleshooting and ensures efficient license utilization.</p><p>One way to accomplish this is by using Ingest Processor to convert robust logs to metrics and use Splunk Observability Cloud as the destination for those metrics. Not only does this make collecting the logs more efficient, you have the added ability of using the newly created metrics in Splunk Observability which can then be correlated with Splunk APM data (traces) and Splunk Infrastructure Monitoring data providing additional troubleshooting context. Because Splunk Observability Cloud uses a streaming metrics pipeline, the metrics can be alerted on in real-time speeding up problem identification. Additionally, you can use the Metrics Pipeline Management functionality to further optimize the data by aggregating, dropping unnecessary fields, and archiving less important or unneeded metrics.</p><p>In the next step you&rsquo;ll create an Ingest Processor Pipeline which will convert Kubernetes Audit Logs to metrics that will be sent to Observability Cloud.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 3. Create an Ingest Pipeline</h1><article class=default><header class=headline></header><h1 id=login-to-splunk-cloud>Login to Splunk Cloud</h1><p>In this section you will create an Ingest Pipeline which will convert Kubernetes Audit Logs to metrics which are sent to the Splunk Observability Cloud workshop organization. Before getting started you will need to access the Splunk Cloud and Ingest Processor SCS Tenant environments provided in the Splunk Show event details.</p><details open class="box cstyle notices green"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-running"></i>
Pre-requisite: Login to Splunk Enterprise Cloud</summary><div class=box-content><p><strong>1.</strong> Open the <strong>Ingest Processor Cloud Stack</strong> URL provided in the Splunk Show event details.</p><p><a href=#R-image-391e32c10f80e47000b3ac23710a5098 class=lightbox-link><img alt="Splunk Cloud Instance Details" class="lazy lightbox figure-image" loading=lazy src=../../images/show_instances_sec.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-391e32c10f80e47000b3ac23710a5098><img alt="Splunk Cloud Instance Details" class="lazy lightbox lightbox-image" loading=lazy src=../../images/show_instances_sec.png></a></p><p><strong>2.</strong> In the Connection info click on the <strong>Stack URL</strong> link to open your Splunk Cloud stack.</p><p><a href=#R-image-7813f706ca003764b25017212b2700aa class=lightbox-link><img alt="Splunk Cloud Connection Details" class="lazy lightbox figure-image" loading=lazy src=../../images/sec_connection_details.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-7813f706ca003764b25017212b2700aa><img alt="Splunk Cloud Connection Details" class="lazy lightbox lightbox-image" loading=lazy src=../../images/sec_connection_details.png></a></p><p><strong>3.</strong> Use the <code>admin</code> username and password to login to Splunk Cloud.</p><p><a href=#R-image-c5a45b48adab6042352cb1451cc6236d class=lightbox-link><img alt="Splunk Cloud Login" class="lazy lightbox figure-image" loading=lazy src=../../images/sec_login.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c5a45b48adab6042352cb1451cc6236d><img alt="Splunk Cloud Login" class="lazy lightbox lightbox-image" loading=lazy src=../../images/sec_login.png></a></p><p><strong>4.</strong> After logging in, if prompted, accept the Terms of Service and click <strong>OK</strong></p><p><a href=#R-image-c807f26920c99a43bbf7bc5c4943618c class=lightbox-link><img alt="Splunk Cloud Login" class="lazy lightbox figure-image" loading=lazy src=../../images/sec_terms.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c807f26920c99a43bbf7bc5c4943618c><img alt="Splunk Cloud Login" class="lazy lightbox lightbox-image" loading=lazy src=../../images/sec_terms.png></a></p><p><strong>5.</strong> Navigate back to the Splunk Show event details and select the Ingest Processor SCS Tenant</p><p><a href=#R-image-077c987fa40c8d87e0f8e240c2dbd8a4 class=lightbox-link><img alt="Ingest Processor Connection Details" class="lazy lightbox figure-image" loading=lazy src=../../images/show_instances_scs.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-077c987fa40c8d87e0f8e240c2dbd8a4><img alt="Ingest Processor Connection Details" class="lazy lightbox lightbox-image" loading=lazy src=../../images/show_instances_scs.png></a></p><p><strong>6.</strong> Click on the <strong>Console URL</strong> to access the <strong>Ingest Processor SCS Tenant</strong></p><details open class="box cstyle notices primary"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p><strong>Single Sign-On (SSO)</strong>
Single Sign-on (SSO) is configured between the Splunk Data Management service (‘SCS Tenant’) and Splunk Cloud environments, so if you already logged in to your Splunk Cloud stack you should automatically be logged in to Splunk Data Management service. If you are prompted for credentials, use the credentials provided in the Splunk Cloud Stack on Splunk Show event (listed under the ‘Splunk Cloud Stack’ section.)</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=review-kubernetes-audit-logs>Review Kubernetes Audit Logs</h1><p>In this section you will review the Kubernetes Audit Logs that are being collected. You can see that the events are quite robust, which can make charting them inefficient. To address this, you will create an Ingest Pipeline in Ingest Processor that will convert these events to metrics that will be sent to Splunk Observability Cloud. This will allow you to chart the events much more efficiently and take advantage of the real-time streaming metrics in Splunk Observability Cloud.</p><details open class="box cstyle notices green"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-running"></i>
Exercise: Create Ingest Pipeline</summary><div class=box-content><p><strong>1.</strong> Open your <strong>Ingest Processor Cloud Stack</strong> instance using the URL provided in the Splunk Show workshop details.</p><p><strong>2.</strong> Navigate to <strong>Apps</strong> → <strong>Search and Reporting</strong></p><p><a href=#R-image-69d06f7a3181e3d8b55706b55f4122b2 class=lightbox-link><img alt="Search and Reporting" class="lazy lightbox figure-image" loading=lazy src="../../images/search_and_reporting.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-69d06f7a3181e3d8b55706b55f4122b2><img alt="Search and Reporting" class="lazy lightbox lightbox-image" loading=lazy src="../../images/search_and_reporting.png?width=20vw"></a></p><p><strong>3.</strong> In the search bar, enter the following SPL search string.</p><details open class="box cstyle notices primary"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p>Make sure to replace <code>USER_ID</code> with the User ID provided in your Splunk Show instance information.</p></div></details><div class="highlight wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=c1>### Replace USER_ID with the User ID provided in your Splunk Show instance information</span>
</span></span><span class=line><span class=cl><span class=nv>index</span><span class=o>=</span>main <span class=nv>sourcetype</span><span class=o>=</span><span class=s2>&#34;kube:apiserver:audit:USER_ID&#34;</span></span></span></code></pre></div><p><strong>4.</strong> Press <strong>Enter</strong> or click the green magnifying glass to run the search.</p><p><a href=#R-image-f1be1561eea1e9fc6506fc9465d7629c class=lightbox-link><img alt="Kubernetes Audit Log" class="lazy lightbox figure-image" loading=lazy src=../../images/k8s_audit_log.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-f1be1561eea1e9fc6506fc9465d7629c><img alt="Kubernetes Audit Log" class="lazy lightbox lightbox-image" loading=lazy src=../../images/k8s_audit_log.png></a></p><details open class="box cstyle notices info"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-info-circle"></i>
Note</summary><div class=box-content><p>You should now see the Kubernetes Audit Logs for your environment. Notice that the events are fairly robust. Explore the available fields and start to think about what information would be good candidates for metrics and dimensions. Ask yourself: What fields would I like to chart, and how would I like to be able to filter, group, or split those fields?</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=create-an-ingest-pipeline>Create an Ingest Pipeline</h1><p>In this section you will create an Ingest Pipeline which will convert Kubernetes Audit Logs to metrics which are sent to the Splunk Observability Cloud workshop organization.</p><details open class="box cstyle notices green"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-running"></i>
Exercise: Create Ingest Pipeline</summary><div class=box-content><p><strong>1.</strong> Open the <strong>Ingest Processor SCS Tenant</strong> using the connection details provided in the Splunk Show event.</p><p><a href=#R-image-2c5cf89da4d08d1b8aa344c3cc4a9be2 class=lightbox-link><img alt="Launch Splunk Cloud Platform" class="lazy lightbox figure-image" loading=lazy src="../../images/data_management_home.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-2c5cf89da4d08d1b8aa344c3cc4a9be2><img alt="Launch Splunk Cloud Platform" class="lazy lightbox lightbox-image" loading=lazy src="../../images/data_management_home.png?width=40vw"></a></p><details open class="box cstyle notices primary"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p>When you open the <strong>Ingest Processor SCS Tenant</strong>, if you are taken to a welcome page, click on <strong>Launch</strong> under <strong>Splunk Cloud Platform</strong> to be taken to the Data Management page where you will configure the Ingest Pipeline.</p><p><a href=#R-image-d013a3b485f6fb7accf78d5d00d94bff class=lightbox-link><img alt="Launch Splunk Cloud Platform" class="lazy lightbox figure-image" loading=lazy src=../../images/launch_scp.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-d013a3b485f6fb7accf78d5d00d94bff><img alt="Launch Splunk Cloud Platform" class="lazy lightbox lightbox-image" loading=lazy src=../../images/launch_scp.png></a></p></div></details><p><strong>2.</strong> From the Splunk Data Management console select <strong>Pipelines</strong> → <strong>New pipeline</strong> → <strong>Ingest Processor pipeline</strong>.</p><p><a href=#R-image-638827ee805aa6f056e3ece538848541 class=lightbox-link><img alt="New Ingest Processor Pipeline" class="lazy lightbox figure-image" loading=lazy src="../../images/new_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-638827ee805aa6f056e3ece538848541><img alt="New Ingest Processor Pipeline" class="lazy lightbox lightbox-image" loading=lazy src="../../images/new_pipeline.png?width=40vw"></a></p><p><strong>3.</strong> In the <strong>Get started</strong> step of the Ingest Processor configuration page select <strong>Blank Pipeline</strong> and click <strong>Next</strong>.</p><p><a href=#R-image-8433feddddc0f292d0f4691d85b4f3a2 class=lightbox-link><img alt="Blank Ingest Processor Pipeline" class="lazy lightbox figure-image" loading=lazy src="../../images/blank_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-8433feddddc0f292d0f4691d85b4f3a2><img alt="Blank Ingest Processor Pipeline" class="lazy lightbox lightbox-image" loading=lazy src="../../images/blank_pipeline.png?width=40vw"></a></p><p><strong>4.</strong> In the <strong>Define your pipeline’s partition</strong> step of the Ingest Processor configuration page select <strong>Partition by sourcetype</strong>. Select the <strong>= equals</strong> Operator and enter <code>kube:apiserver:audit:USER_ID</code> (Be sure to replace USER_ID with the User ID you were assigned) for the value. Click <strong>Apply</strong>.</p><p><a href=#R-image-0657a2532728fb8a4050a1b89539e8e8 class=lightbox-link><img alt="Add Partition" class="lazy lightbox figure-image" loading=lazy src="../../images/add_partition.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-0657a2532728fb8a4050a1b89539e8e8><img alt="Add Partition" class="lazy lightbox lightbox-image" loading=lazy src="../../images/add_partition.png?width=40vw"></a></p><p><strong>5.</strong> Click <strong>Next</strong></p><p><strong>6.</strong> In the <strong>Add sample data</strong> step of the Ingest Processor configuration page select <strong>Capture new snapshot</strong>. Enter <code>k8s_audit_USER_ID</code> (Be sure to replace USER_ID with the User ID you were assigned) for the Snapshot name and click <strong>Capture</strong>.</p><p><a href=#R-image-ab68703245fa43b94afee02b47ac4a05 class=lightbox-link><img alt="Capture Snapshot" class="lazy lightbox figure-image" loading=lazy src="../../images/capture_snapshot.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-ab68703245fa43b94afee02b47ac4a05><img alt="Capture Snapshot" class="lazy lightbox lightbox-image" loading=lazy src="../../images/capture_snapshot.png?width=40vw"></a></p><p><strong>7.</strong> Make sure your newly created snapshot (<code>k8s_audit_USER_ID</code>) is selected and then click <strong>Next</strong>.</p><p><a href=#R-image-3e5c029c2764117a63b059b28df4cad8 class=lightbox-link><img alt="Configure Snapshot Sourcetype" class="lazy lightbox figure-image" loading=lazy src="../../images/capture_snapshot_sourcetype.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-3e5c029c2764117a63b059b28df4cad8><img alt="Configure Snapshot Sourcetype" class="lazy lightbox lightbox-image" loading=lazy src="../../images/capture_snapshot_sourcetype.png?width=20vw"></a></p><p><strong>8.</strong> In the <strong>Select a metrics destination</strong> step of the Ingest Processor configuration page select <strong>show_o11y_org</strong>. Click <strong>Next</strong>.</p><p><a href=#R-image-dc865e73bd694c46096cda3d5ec4627b class=lightbox-link><img alt="Metrics Destination" class="lazy lightbox figure-image" loading=lazy src="../../images/metrics_destination.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-dc865e73bd694c46096cda3d5ec4627b><img alt="Metrics Destination" class="lazy lightbox lightbox-image" loading=lazy src="../../images/metrics_destination.png?width=20vw"></a></p><p><strong>9.</strong> In the <strong>Select a data destination</strong> step of the Ingest Processor configuration page select <strong>splunk_indexer</strong>. Under <strong>Specify how you want your events to be routed to an index</strong> select <strong>Default</strong>. Click <strong>Done</strong>.</p><p><a href=#R-image-c94523dd363d7db0d7371f67a4ecdf30 class=lightbox-link><img alt="Event Routing" class="lazy lightbox figure-image" loading=lazy src="../../images/event_routing.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c94523dd363d7db0d7371f67a4ecdf30><img alt="Event Routing" class="lazy lightbox lightbox-image" loading=lazy src="../../images/event_routing.png?width=20vw"></a></p><p><strong>10.</strong> In the <strong>Pipeline search field</strong> replace the default search with the following.</p><details open class="box cstyle notices primary"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p><strong>Replace <code>UNIQUE_FIELD</code> in the metric name with a unique value (such as your initials) which will be used to identify your metric in Observability Cloud.</strong></p></div></details><div class="highlight wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>/*A valid SPL2 statement for a pipeline must start with &#34;$pipeline&#34;, and include &#34;from $source&#34; and &#34;into $destination&#34;.*/
</span></span><span class=line><span class=cl>/* Import logs_to_metrics */
</span></span><span class=line><span class=cl>import logs_to_metrics from /splunk/ingest/commands
</span></span><span class=line><span class=cl>$pipeline =
</span></span><span class=line><span class=cl>| from $source
</span></span><span class=line><span class=cl>| thru [
</span></span><span class=line><span class=cl>        //define the metric name, type, and value for the Kubernetes Events
</span></span><span class=line><span class=cl>        //
</span></span><span class=line><span class=cl>        // REPLACE UNIQUE_FIELD WITH YOUR INITIALS
</span></span><span class=line><span class=cl>        //
</span></span><span class=line><span class=cl>        | logs_to_metrics name=&#34;k8s_audit_UNIQUE_FIELD&#34; metrictype=&#34;counter&#34; value=1 time=_time
</span></span><span class=line><span class=cl>        | into $metrics_destination
</span></span><span class=line><span class=cl>    ]
</span></span><span class=line><span class=cl>| eval index = &#34;kube_logs&#34;
</span></span><span class=line><span class=cl>| into $destination;</span></span></code></pre></div><details open class="box cstyle notices info"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-lightbulb"></i>
New to SPL2?</summary><div class=box-content><p>Here is a breakdown of what the SPL2 query is doing:</p><ul><li>First, you are importing the built-in <code>logs_to_metrics</code> command which will be used to convert the kubernetes events to metrics.</li><li>You&rsquo;re using the source data, which you can see on the right is any event from the <code>kube:apiserver:audit</code> sourcetype.</li><li>Now, you use the <code>thru</code> command which writes the source dataset to the following command, in this case <code>logs_to_metrics</code>.</li><li>You can see that the metric name (<code>k8s_audit</code>), metric type (<code>counter</code>), value, and timestamp are all provided for the metric. You’re using a value of 1 for this metric because we want to count the number of times the event occurs.</li><li>Next, you choose the destination for the metric using the into <code>$metrics_destintation</code> command, which is our Splunk Observability Cloud organization</li><li>Finally, you can send the raw log events to another destination, in this case another index, so they are retained if we ever need to access them.</li></ul></div></details><p><strong>11.</strong> In the upper-right corner click the <strong>Preview</strong> button <a href=#R-image-e99eb27f7004cec9dca0874b0251201f class=lightbox-link><img alt="Preview Button" class="inline lazy lightbox figure-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-e99eb27f7004cec9dca0874b0251201f><img alt="Preview Button" class="inline lazy lightbox lightbox-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline"></a> or press CTRL+Enter (CMD+Enter on Mac). From the <strong>Previewing $pipeline</strong> dropdown select <strong>$metrics_destination</strong>. Confirm you are seeing a preview of the metrics that will be sent to Splunk Observability Cloud.</p><p><a href=#R-image-d410ba7574e0ca24d669559e23233fe5 class=lightbox-link><img alt="Preview Pipeline" class="lazy lightbox figure-image" loading=lazy src="../../images/preview_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-d410ba7574e0ca24d669559e23233fe5><img alt="Preview Pipeline" class="lazy lightbox lightbox-image" loading=lazy src="../../images/preview_pipeline.png?width=40vw"></a></p><p><strong>12.</strong> In the upper-right corner click the <strong>Save pipeline</strong> button <a href=#R-image-93d9916c448e6d3fc852b6b47a6d3d03 class=lightbox-link><img alt="Save Pipeline Button" class="inline lazy lightbox figure-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-93d9916c448e6d3fc852b6b47a6d3d03><img alt="Save Pipeline Button" class="inline lazy lightbox lightbox-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline"></a>. Enter <code>Kubernetes Audit Logs2Metrics USER_ID</code> for your pipeline name and click <strong>Save</strong>.</p><p><a href=#R-image-ecb90a57023481aaba5632394f13584c class=lightbox-link><img alt="Save Pipeline Dialog" class="lazy lightbox figure-image" loading=lazy src="../../images/save_pipeline_dialog.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-ecb90a57023481aaba5632394f13584c><img alt="Save Pipeline Dialog" class="lazy lightbox lightbox-image" loading=lazy src="../../images/save_pipeline_dialog.png?width=40vw"></a></p><p><strong>13.</strong> After clicking save you will be asked if you would like to apply the newly created pipeline. Click <strong>Yes, apply</strong>.</p><p><a href=#R-image-60c1d7b3a99184aa23a03111591ad660 class=lightbox-link><img alt="Apply Pipeline Dialog" class="lazy lightbox figure-image" loading=lazy src="../../images/apply_pipeline_dialog.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-60c1d7b3a99184aa23a03111591ad660><img alt="Apply Pipeline Dialog" class="lazy lightbox lightbox-image" loading=lazy src="../../images/apply_pipeline_dialog.png?width=40vw"></a></p><details open class="box cstyle notices info"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-info-circle"></i>
Note</summary><div class=box-content><p>The Ingest Pipeline should now be sending metrics to Splunk Observability Cloud. Keep this tab open as it will be used it again in the next section.</p><p>In the next step you&rsquo;ll confirm the pipeline is working by viewing the metrics you just created in Splunk Observability Cloud.</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=confirm-metrics-in-observability-cloud>Confirm Metrics in Observability Cloud</h1><p>Now that an Ingest Pipeline has been configured to convert Kubernetes Audit Logs into metrics and send them to Splunk Observability Cloud the metrics should be available. To confirm the metrics are being collected complete the following steps:</p><details open class="box cstyle notices green"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-running"></i>
Exercise: Confirm Metrics in Splunk Observability Cloud</summary><div class=box-content><p><strong>1.</strong> Login to the <strong>Splunk Observability Cloud</strong> organization you were invited for the workshop. In the upper-right corner, click the <strong>+</strong> Icon → <strong>Chart</strong> to create a new chart.</p><p><a href=#R-image-365b15c7c5f863b7e6c8fcad8d2674ee class=lightbox-link><img alt="Create New Chart" class="lazy lightbox figure-image" loading=lazy src="../../images/create_new_chart.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-365b15c7c5f863b7e6c8fcad8d2674ee><img alt="Create New Chart" class="lazy lightbox lightbox-image" loading=lazy src="../../images/create_new_chart.png?width=40vw"></a></p><p><strong>2.</strong> In the <strong>Plot Editor</strong> of the newly created chart enter the metric name you used while configuring the <strong>Ingest Pipeline</strong>.</p><p><a href=#R-image-c28bd15997f10a189a64f229e54605ec class=lightbox-link><img alt="Review Metric" class="lazy lightbox figure-image" loading=lazy src="../../images/review_metric.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c28bd15997f10a189a64f229e54605ec><img alt="Review Metric" class="lazy lightbox lightbox-image" loading=lazy src="../../images/review_metric.png?width=40vw"></a></p><details open class="box cstyle notices info"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-info-circle"></i>
Info</summary><div class=box-content><p>You should see the metric you created in the Ingest Pipeline. Keep this tab open as it will be used again in the next section.</p><p>In the next step you will update the ingest pipeline to add dimensions to the metric, so you have additional context for alerting and troubleshooting.</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article></section><article class=default><header class=headline></header><h1 id=update-pipeline-and-visualize-metrics>Update Pipeline and Visualize Metrics</h1><h2 id=context-matters>Context Matters</h2><p>In the previous section, you reviewed the raw Kubernetes audit logs and created an Ingest Processor Pipeline to convert them to metrics and send those metrics to Splunk Observability Cloud.</p><p>Now that this pipeline is defined we are collecting the new metrics in Splunk Observability Cloud. This is a great start; however, you will only see a single metric showing the total number of Kubernetes audit events for a given time period. It would be much more valuable to add dimensions so that you can split the metric by the event type, user, response status, and so on.</p><p>In this section you will update the Ingest Processor Pipeline to include additional dimensions from the Kubernetes audit logs to the metrics that are being collected. This will allow you to further filter, group, visualize, and alert on specific aspects of the audit logs. After updating the metric, you will create a new dashboard showing the status of the different types of actions associated with the logs.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 4. Update Pipeline and Visualize Metrics</h1><article class=default><header class=headline></header><h1 id=update-ingest-pipeline>Update Ingest Pipeline</h1><details open class="box cstyle notices green"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-running"></i>
Exercise: Update Ingest Pipeline</summary><div class=box-content><p><strong>1.</strong> Navigate back to the configuration page for the Ingest Pipeline you created in the previous step.</p><p><a href=#R-image-46f128606b4e79288306ddff0f4f7263 class=lightbox-link><img alt="Ingest Pipeline" class="lazy lightbox figure-image" loading=lazy src="../../images/ingest_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-46f128606b4e79288306ddff0f4f7263><img alt="Ingest Pipeline" class="lazy lightbox lightbox-image" loading=lazy src="../../images/ingest_pipeline.png?width=40vw"></a></p><p><strong>2.</strong> To add dimensions to the metric from the raw Kubernetes audit logs update the SPL2 query you created for the pipeline by replacing the <code>logs_to_metrics</code> portion of the query with the following:</p><details open class="box cstyle notices primary"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p><strong>Be sure to update the metric name field (<code>name="k8s_audit_UNIQUE_FIELD"</code>) to the name you provided in the original pipeline</strong></p></div></details><div class="highlight wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>| logs_to_metrics name=&#34;k8s_audit_UNIQUE_FIELD&#34; metrictype=&#34;counter&#34; value=1 time=_time dimensions={&#34;level&#34;: _raw.level, &#34;response_status&#34;: _raw.responseStatus.code, &#34;namespace&#34;: _raw.objectRef.namespace, &#34;resource&#34;: _raw.objectRef.resource, &#34;user&#34;: _raw.user.username, &#34;action&#34;: _raw.verb}</span></span></code></pre></div><details open class="box cstyle notices info"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-info"></i>
Note</summary><div class=box-content><p>Using the <code>dimensions</code> field in the SPL2 query you can add dimensions from the raw events to the metrics that will be sent to Splunk Observability Cloud. In this case you are adding the event response status, namespace, Kubernetes resource, user, and verb (action that was performed). These dimensions can be used to create more granular dashboards and alerts.</p><p>You should consider adding any common tags across your services so that you can take advantage of context propagation and related content in Splunk Observability Cloud.</p></div></details><p>The updated pipeline should now be the following:</p><div class="highlight wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>/*A valid SPL2 statement for a pipeline must start with &#34;$pipeline&#34;, and include &#34;from $source&#34; and &#34;into $destination&#34;.*/
</span></span><span class=line><span class=cl>/* Import logs_to_metrics */
</span></span><span class=line><span class=cl>import logs_to_metrics from /splunk/ingest/commands
</span></span><span class=line><span class=cl>$pipeline =
</span></span><span class=line><span class=cl>| from $source
</span></span><span class=line><span class=cl>| thru [
</span></span><span class=line><span class=cl>        //define the metric name, type, and value for the Kubernetes Events
</span></span><span class=line><span class=cl>        //
</span></span><span class=line><span class=cl>        // REPLACE UNIQUE_FIELD WITH YOUR INITIALS
</span></span><span class=line><span class=cl>        //
</span></span><span class=line><span class=cl>        | logs_to_metrics name=&#34;k8s_audit_UNIQUE_FIELD&#34; metrictype=&#34;counter&#34; value=1 time=_time dimensions={&#34;level&#34;: _raw.level, &#34;response_status&#34;: _raw.responseStatus.code, &#34;namespace&#34;: _raw.objectRef.namespace, &#34;resource&#34;: _raw.objectRef.resource, &#34;user&#34;: _raw.user.username, &#34;action&#34;: _raw.verb}
</span></span><span class=line><span class=cl>        | into $metrics_destination
</span></span><span class=line><span class=cl>    ]
</span></span><span class=line><span class=cl>| eval index = &#34;kube_logs&#34;
</span></span><span class=line><span class=cl>| into $destination;</span></span></code></pre></div><p><strong>3.</strong> In the upper-right corner click the <strong>Preview</strong> button <a href=#R-image-4c23c43f997eaae59de3d2fe7ccadcc7 class=lightbox-link><img alt="Preview Button" class="inline lazy lightbox figure-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-4c23c43f997eaae59de3d2fe7ccadcc7><img alt="Preview Button" class="inline lazy lightbox lightbox-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline"></a> or press CTRL+Enter (CMD+Enter on Mac). From the <strong>Previewing $pipeline</strong> dropdown select <strong>$metrics_destination</strong>. Confirm you are seeing a preview of the metrics that will be sent to Splunk Observability Cloud.</p><p><a href=#R-image-4aa82558b7c404835c7f43fbc24714c3 class=lightbox-link><img alt="Ingest Pipeline Dimensions" class="lazy lightbox figure-image" loading=lazy src="../../images/ingest_pipeline_dimensions.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-4aa82558b7c404835c7f43fbc24714c3><img alt="Ingest Pipeline Dimensions" class="lazy lightbox lightbox-image" loading=lazy src="../../images/ingest_pipeline_dimensions.png?width=40vw"></a></p><p><strong>4.</strong> Confirm you are seeing the dimensions in the dimensions column of the preview table. You can view the entire dimensions object by clicking into the table.</p><p><a href=#R-image-f4b73e8388df0aebe8fa19e763f2b61e class=lightbox-link><img alt="Ingest Pipeline Dimensions Review" class="lazy lightbox figure-image" loading=lazy src="../../images/ingest_pipeline_dimensions_field.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-f4b73e8388df0aebe8fa19e763f2b61e><img alt="Ingest Pipeline Dimensions Review" class="lazy lightbox lightbox-image" loading=lazy src="../../images/ingest_pipeline_dimensions_field.png?width=40vw"></a></p><p><strong>5.</strong> In the upper-right corner click the <strong>Save pipeline</strong> button <a href=#R-image-e0a21732f827d39457e77b6065ae5265 class=lightbox-link><img alt="Save Pipeline Button" class="inline lazy lightbox figure-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-e0a21732f827d39457e77b6065ae5265><img alt="Save Pipeline Button" class="inline lazy lightbox lightbox-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline"></a>. On the “You are editing an active pipeline modal” click <strong>Save</strong>.</p><p><a href=#R-image-3ddb2725b8cacd29a738213243baf626 class=lightbox-link><img alt="Save Updated Pipeline" class="lazy lightbox figure-image" loading=lazy src="../../images/save_updated_pipeline.png?width=30vw" style=height:auto;width:30vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-3ddb2725b8cacd29a738213243baf626><img alt="Save Updated Pipeline" class="lazy lightbox lightbox-image" loading=lazy src="../../images/save_updated_pipeline.png?width=30vw"></a></p><details open class="box cstyle notices info"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-info-circle"></i>
Note</summary><div class=box-content><p>Because this pipeline is already active, the changes you made will take effect immediately. Your metric should now be split into multiple metric timeseries using the dimensions you added.</p><p>In the next step you will create a visualization using different dimensions from the Kubernetes audit events.</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=visualize-kubernetes-audit-event-metrics>Visualize Kubernetes Audit Event Metrics</h1><p>Now that your metric has dimensions you will create a chart showing the health of different Kubernetes actions using the <code>verb</code> dimension from the events.</p><details open class="box cstyle notices green"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-running"></i>
Exercise: Visualize Kubernetes Audit Event Metrics</summary><div class=box-content><p><strong>1.</strong> If you closed the chart you created in the previous section, in the upper-right corner, click the <strong>+</strong> Icon → <strong>Chart</strong> to create a new chart.</p><p><a href=#R-image-379b3191ef77664be4718c759da373f6 class=lightbox-link><img alt="Create New Chart" class="lazy lightbox figure-image" loading=lazy src="../../images/create_new_chart.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-379b3191ef77664be4718c759da373f6><img alt="Create New Chart" class="lazy lightbox lightbox-image" loading=lazy src="../../images/create_new_chart.png?width=40vw"></a></p><p><strong>2.</strong> In the <strong>Plot Editor</strong> of the newly created chart enter <code>k8s_audit*</code> in the metric name field. You will use a wildcard here so that you can see all the metrics that are being ingested.</p><p><a href=#R-image-9fe46e3e0e9a08deb42a8707f37fe050 class=lightbox-link><img alt="Review Metric" class="lazy lightbox figure-image" loading=lazy src="../../images/review_metric.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-9fe46e3e0e9a08deb42a8707f37fe050><img alt="Review Metric" class="lazy lightbox lightbox-image" loading=lazy src="../../images/review_metric.png?width=40vw"></a></p><p><strong>3.</strong> Notice the change from one to many metrics, which is when you updated the pipeline to include the dimensions. Now that we have this metric available, let&rsquo;s adjust the chart to show us if any of our actions have errors associated with them.</p><p><a href=#R-image-f3ff8434a8389bfac1422d558943942b class=lightbox-link><img alt="Metric Timeseries" class="lazy lightbox figure-image" loading=lazy src="../../images/metric_timeseries.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-f3ff8434a8389bfac1422d558943942b><img alt="Metric Timeseries" class="lazy lightbox lightbox-image" loading=lazy src="../../images/metric_timeseries.png?width=40vw"></a></p><p>First you&rsquo;ll filter the Kubernetes events to only those that were not successful using the HTTP response code which is available in the <strong>response_status</strong> field. We only want events that have a response code of <strong>409</strong>, which indicates that there was a conflict (for example a trying to create a resource that already exists) or <strong>503</strong>, which indicates that the API was unresponsive for the request.</p><p><strong>4.</strong> In the plot editor of your chart click the <strong>Add filter</strong>, use <strong>response_status</strong> for the field and select <strong>409.0</strong> and <strong>503.0</strong> for the values.</p><p>Next, you’ll add a function to the chart which will calculate the total number of events grouped by the <strong>resource</strong>, <strong>action</strong>, and <strong>response status</strong>. This will allow us to see exactly which actions and the associated resources had errors. Now we are only looking at Kubernetes events that were not successful.</p><p><strong>5.</strong> Click <strong>Add analytics</strong> → <strong>Sum</strong> → <strong>Sum:Aggregation</strong> and add <strong>resource</strong>, <strong>action</strong>, and <strong>response_status</strong> in the <strong>Group by</strong> field.</p><p><a href=#R-image-d9d82de5d61f96c8298da9cc7a256b10 class=lightbox-link><img alt="Add Metric Filters" class="lazy lightbox figure-image" loading=lazy src="../../images/add_metric_filters.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-d9d82de5d61f96c8298da9cc7a256b10><img alt="Add Metric Filters" class="lazy lightbox lightbox-image" loading=lazy src="../../images/add_metric_filters.png?width=40vw"></a></p><p><strong>6.</strong> Using the chart type along the top buttons, change the chart to a <strong>heatmap</strong>. Next to the <strong>Plot editor</strong>, click <strong>Chart options</strong>. In the <strong>Group by</strong> section select <strong>response_status</strong> then <strong>action</strong>. Change the <strong>Color threshold</strong> from <strong>Auto</strong> to <strong>Fixed</strong>. Click the blue <strong>+ button</strong> to add another threshold. Change the <strong>Down arrow to Yellow</strong>, the <strong>Middle to orange</strong>. Leave the <strong>Up arrow as red</strong>. Enter <strong>5 for the middle threshold</strong> and <strong>20 for the upper threshold</strong>.</p><p><a href=#R-image-e48bdba8818190fc8c7d2c7b47db8e56 class=lightbox-link><img alt="Configure Thresholds" class="lazy lightbox figure-image" loading=lazy src="../../images/configure_thresholds.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-e48bdba8818190fc8c7d2c7b47db8e56><img alt="Configure Thresholds" class="lazy lightbox lightbox-image" loading=lazy src="../../images/configure_thresholds.png?width=40vw"></a></p><p><strong>7.</strong> In the upper right corner of the chart click the blue <strong>Save as&mldr;</strong> <a href=#R-image-c4413441ffa742da2542e12451879840 class=lightbox-link><img alt="Preview Button" class="inline lazy lightbox figure-image" loading=lazy src="../../images/save_as_btn.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c4413441ffa742da2542e12451879840><img alt="Preview Button" class="inline lazy lightbox lightbox-image" loading=lazy src="../../images/save_as_btn.png?height=20px&classes=inline"></a> button. Enter a name for your chart (For Example: Kubernetes Audit Logs - Conflicts and Failures).</p><p><a href=#R-image-bafad5a3e6eff4722c1b89e0d6f9f60f class=lightbox-link><img alt="Chart Name" class="lazy lightbox figure-image" loading=lazy src=../../images/chart_name.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-bafad5a3e6eff4722c1b89e0d6f9f60f><img alt="Chart Name" class="lazy lightbox lightbox-image" loading=lazy src=../../images/chart_name.png></a></p><p><strong>8.</strong> On the <strong>Choose a dashboard</strong> select <strong>New dashboard</strong>.</p><p><a href=#R-image-e24c2828c48e29cf130543c55d8bc453 class=lightbox-link><img alt="New Dashboard" class="lazy lightbox figure-image" loading=lazy src=../../images/new_dashboard.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-e24c2828c48e29cf130543c55d8bc453><img alt="New Dashboard" class="lazy lightbox lightbox-image" loading=lazy src=../../images/new_dashboard.png></a></p><p><strong>9.</strong> Enter a name for your dashboard that includes your initials, so you can easily find it later. Click <strong>Save</strong>.</p><p><a href=#R-image-d433fb338e95f0f81924f900e2621c90 class=lightbox-link><img alt="New Dashboard Name" class="lazy lightbox figure-image" loading=lazy src=../../images/dashboard_name.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-d433fb338e95f0f81924f900e2621c90><img alt="New Dashboard Name" class="lazy lightbox lightbox-image" loading=lazy src=../../images/dashboard_name.png></a></p><p><strong>10.</strong> Make sure the new dashboard you just created is selected and click <strong>Ok</strong>.</p><p><a href=#R-image-2b72ba37d5f1efd738d96b6c10819790 class=lightbox-link><img alt="Save New Dashboard" class="lazy lightbox figure-image" loading=lazy src=../../images/save_new_dashboard.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-2b72ba37d5f1efd738d96b6c10819790><img alt="Save New Dashboard" class="lazy lightbox lightbox-image" loading=lazy src=../../images/save_new_dashboard.png></a></p><p>You should now be taken to your new Kubernetes Audit Events dashboard with the chart you created. You can add new charts from other metrics in your environment, such as application errors and response times from the applications running in the Kubernetes cluster, or other Kubernetes metrics such as pod phase, pod memory utilization, etc. giving you a correlated view of your Kubernetes environment from cluster events to application health.</p><p><a href=#R-image-b67dcaff04f2abe0fa564f8f58c8ffa9 class=lightbox-link><img alt="Audit Dashboard" class="lazy lightbox figure-image" loading=lazy src="../../images/audit_dashboard.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b67dcaff04f2abe0fa564f8f58c8ffa9><img alt="Audit Dashboard" class="lazy lightbox lightbox-image" loading=lazy src="../../images/audit_dashboard.png?width=40vw"></a></p></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article></section><article class=default><header class=headline></header><h1 id=conclusion>Conclusion</h1><p>In this workshop, you walked through the entire process of optimizing Kubernetes log management by converting detailed log events into actionable metrics using <strong>Splunk Ingest Pipelines</strong>. You started by defining a pipeline that efficiently converts Kubernetes audit logs into metrics, drastically reducing the data volume while retaining critical information. You then ensured the raw log events were securely stored in S3 for long-term retention and deeper analysis.</p><p><a href=#R-image-2563660cc2db7bad373a01103e88ac17 class=lightbox-link><img alt="Kubernetes Audit Event" class="lazy lightbox figure-image" loading=lazy src="../images/audit_event.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-2563660cc2db7bad373a01103e88ac17><img alt="Kubernetes Audit Event" class="lazy lightbox lightbox-image" loading=lazy src="../images/audit_event.png?width=40vw"></a></p><p>Next, you demonstrated how to enhance these metrics by adding key dimensions from the raw events, enabling us to drill down into specific actions and resources. you created a chart that filtered the metrics to focus on errors, breaking them out by resource and action. This allowed us to pinpoint exactly where issues were occurring in real-time.</p><p><a href=#R-image-7c9ecc25cb3a3b8964c7ed64bd8af9ed class=lightbox-link><img alt="Ingest Pipeline" class="lazy lightbox figure-image" loading=lazy src="../images/ingest_pipeline_dimensions.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-7c9ecc25cb3a3b8964c7ed64bd8af9ed><img alt="Ingest Pipeline" class="lazy lightbox lightbox-image" loading=lazy src="../images/ingest_pipeline_dimensions.png?width=40vw"></a></p><p>The real-time architecture of <strong>Splunk Observability Cloud</strong> means that these metrics can trigger alerts the moment an issue is detected, significantly reducing the Mean Time to Detection (MTTD). Additionally, you showed how this chart can be easily saved to new or existing dashboards, ensuring ongoing visibility and monitoring of critical metrics.</p><p><a href=#R-image-9899f9ecca72943f75646bbe56a2a431 class=lightbox-link><img alt="Audit Dashboard" class="lazy lightbox figure-image" loading=lazy src="../images/audit_dashboard.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-9899f9ecca72943f75646bbe56a2a431><img alt="Audit Dashboard" class="lazy lightbox lightbox-image" loading=lazy src="../images/audit_dashboard.png?width=40vw"></a></p><p>The value behind this approach is clear: by converting logs to metrics using <strong>Ingest Processor</strong>, you not only streamline data processing and reduce storage costs but also gain the ability to monitor and respond to issues in real-time using <strong>Splunk Observability Cloud</strong>. This results in faster problem resolution, improved system reliability, and more efficient resource utilization, all while maintaining the ability to retain and access the original logs for compliance or deeper analysis.</p><center><h1>Happy Splunking!</h1></center><p><a href=#R-image-66d05b6c301c4b80d588d6b4e3452ecb class=lightbox-link><img alt="Dancing Buttercup" class="lazy lightbox figure-image" loading=lazy src="../images/Splunk-dancing-buttercup-GIF-103.gif?width=30vw" style=height:auto;width:30vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-66d05b6c301c4b80d588d6b4e3452ecb><img alt="Dancing Buttercup" class="lazy lightbox lightbox-image" loading=lazy src="../images/Splunk-dancing-buttercup-GIF-103.gif?width=30vw"></a></p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article></section></div></main></div><script src=/observability-workshop/v5.96/js/clipboard/clipboard.min.js?1751877988 defer></script><script src=/observability-workshop/v5.96/js/perfect-scrollbar/perfect-scrollbar.min.js?1751877988 defer></script><script src=/observability-workshop/v5.96/js/theme.min.js?1751877988 defer></script></body></html>